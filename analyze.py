"""
æ¨¡å‹åˆ†æå·¥å…· - å¯è§†åŒ–CNNå„å±‚çš„è¾“å‡ºå’Œæ¨¡å‹æ€§èƒ½
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os

# ==================== è®¾ç½®ä¸­æ–‡å­—ä½“ ====================
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # ä½¿ç”¨é»‘ä½“æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# é…ç½®
MODEL_PATH = "models/mnist_cnn.pth"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
RESULTS_DIR = "analysis_results"
os.makedirs(RESULTS_DIR, exist_ok=True)

# ==================== æ¨¡å‹å®šä¹‰ï¼ˆå¿…é¡»å’Œtrain.pyä¸€è‡´ï¼‰ ====================
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(12544, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ==================== ç‰¹æ®Šæ¨¡å‹ï¼šç”¨äºæå–ä¸­é—´å±‚è¾“å‡º ====================
class NetWithHooks(nn.Module):
    """èƒ½çœ‹åˆ°ä¸­é—´å±‚è¾“å‡ºçš„æ¨¡å‹"""
    def __init__(self, base_model):
        super().__init__()
        self.conv1 = base_model.conv1
        self.conv2 = base_model.conv2
        self.pool = base_model.pool
        self.fc1 = base_model.fc1
        self.fc2 = base_model.fc2
        
        # å­˜å‚¨ä¸­é—´è¾“å‡º
        self.features = {}
    
    def forward(self, x):
        # Conv1
        x = F.relu(self.conv1(x))
        self.features['conv1'] = x.detach()
        
        # Conv2 + Pool
        x = F.relu(self.conv2(x))
        self.features['conv2'] = x.detach()
        x = self.pool(x)
        self.features['pool'] = x.detach()
        
        # Flatten
        x = x.view(x.size(0), -1)
        
        # FC1
        x = F.relu(self.fc1(x))
        self.features['fc1'] = x.detach()
        
        # FC2
        x = self.fc2(x)
        return x


def load_model():
    """åŠ è½½æ¨¡å‹"""
    model = Net().to(DEVICE)
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.eval()
    return model


def visualize_conv_filters(model, save_path="conv_filters.png"):
    """
    å¯è§†åŒ–ç¬¬ä¸€å±‚å·ç§¯æ ¸
    æ¯ä¸ªå·ç§¯æ ¸éƒ½æ˜¯ä¸€ä¸ª3Ã—3çš„å°å›¾åƒï¼Œå­¦åˆ°äº†ä»€ä¹ˆç‰¹å¾
    """
    print("\nğŸ¨ å¯è§†åŒ–Conv1çš„32ä¸ªå·ç§¯æ ¸...")
    
    weights = model.conv1.weight.data.cpu().numpy()  # shape: (32, 1, 3, 3)
    
    # æ ‡å‡†åŒ–åˆ°0-1
    weights = (weights - weights.min()) / (weights.max() - weights.min() + 1e-8)
    
    fig, axes = plt.subplots(4, 8, figsize=(12, 8))
    fig.suptitle('Conv1å±‚çš„32ä¸ªå·ç§¯æ ¸ï¼ˆ3Ã—3æ»¤æ³¢å™¨ï¼‰', fontsize=16, fontweight='bold')
    
    for idx, ax in enumerate(axes.flat):
        ax.imshow(weights[idx, 0], cmap='gray')
        ax.axis('off')
        ax.set_title(f'Filter {idx+1}', fontsize=8)
    
    full_path = os.path.join(RESULTS_DIR, save_path)
    plt.tight_layout()
    plt.savefig(full_path, dpi=100, bbox_inches='tight')
    print(f"âœ… å·²ä¿å­˜: {full_path}")
    plt.close()


def visualize_feature_maps(model_with_hooks, test_image, digit_label, save_path="feature_maps.png"):
    """
    å¯è§†åŒ–ä¸€å¼ å›¾åƒåœ¨å„å±‚çš„ç‰¹å¾å›¾
    çœ‹æ¨¡å‹æ˜¯æ€ä¹ˆå¤„ç†è¾“å…¥çš„
    """
    print(f"\nğŸ” å¯è§†åŒ–æ•°å­—'{digit_label}'åœ¨å„å±‚çš„ç‰¹å¾å›¾...")
    
    with torch.no_grad():
        output = model_with_hooks(test_image)
    
    features = model_with_hooks.features
    
    # ========== åŸå§‹å›¾åƒ ==========
    fig, axes = plt.subplots(3, 4, figsize=(14, 10))
    fig.suptitle(f'CNNå„å±‚ç‰¹å¾æå–è¿‡ç¨‹ï¼ˆè¾“å…¥æ•°å­—ï¼š{digit_label}ï¼‰', fontsize=16, fontweight='bold')
    
    # ç¬¬1è¡Œï¼šåŸå§‹å›¾åƒ + Conv1çš„4ä¸ªç‰¹å¾å›¾
    original = test_image.cpu().numpy()[0, 0]
    axes[0, 0].imshow(original, cmap='gray')
    axes[0, 0].set_title('åŸå§‹å›¾åƒ\n(28Ã—28)', fontweight='bold')
    axes[0, 0].axis('off')
    
    conv1_feat = features['conv1'].cpu().numpy()[0]  # shape: (32, 28, 28)
    for i in range(1, 4):
        ax = axes[0, i]
        ax.imshow(conv1_feat[i*8], cmap='hot')
        ax.set_title(f'Conv1æ»¤æ³¢å™¨{i*8+1}\n(28Ã—28)', fontsize=9)
        ax.axis('off')
    
    # ç¬¬2è¡Œï¼šConv2çš„4ä¸ªç‰¹å¾å›¾
    conv2_feat = features['conv2'].cpu().numpy()[0]  # shape: (64, 28, 28)
    for i in range(4):
        ax = axes[1, i]
        ax.imshow(conv2_feat[i*16], cmap='hot')
        ax.set_title(f'Conv2æ»¤æ³¢å™¨{i*16+1}\n(28Ã—28)', fontsize=9)
        ax.axis('off')
    
    # ç¬¬3è¡Œï¼šPoolåçš„ç‰¹å¾å›¾
    pool_feat = features['pool'].cpu().numpy()[0]  # shape: (64, 14, 14)
    for i in range(4):
        ax = axes[2, i]
        ax.imshow(pool_feat[i*16], cmap='hot')
        ax.set_title(f'MaxPoolå\n(14Ã—14)', fontsize=9)
        ax.axis('off')
    
    full_path = os.path.join(RESULTS_DIR, save_path)
    plt.tight_layout()
    plt.savefig(full_path, dpi=100, bbox_inches='tight')
    print(f"âœ… å·²ä¿å­˜: {full_path}")
    plt.close()


def evaluate_and_confusion_matrix(model, test_loader, save_path="confusion_matrix.png"):
    """
    è¯„ä¼°æ¨¡å‹ï¼Œç”Ÿæˆæ··æ·†çŸ©é˜µ
    çœ‹å“ªäº›æ•°å­—æœ€å®¹æ˜“è¢«è¯†åˆ«é”™
    """
    print("\nğŸ“Š è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼‰...")
    
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            preds = outputs.argmax(dim=1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    
    # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
    accuracy = (all_preds == all_labels).mean()
    print(f"æ•´ä½“å‡†ç¡®ç‡: {accuracy*100:.2f}%")
    
    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    
    # ç»˜åˆ¶
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,
                xticklabels=range(10), yticklabels=range(10))
    ax.set_xlabel('é¢„æµ‹ç»“æœ', fontsize=12, fontweight='bold')
    ax.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12, fontweight='bold')
    ax.set_title(f'æ··æ·†çŸ©é˜µï¼ˆæ•´ä½“å‡†ç¡®ç‡ï¼š{accuracy*100:.2f}%ï¼‰', fontsize=14, fontweight='bold')
    
    full_path = os.path.join(RESULTS_DIR, save_path)
    plt.tight_layout()
    plt.savefig(full_path, dpi=100, bbox_inches='tight')
    print(f"âœ… å·²ä¿å­˜: {full_path}")
    plt.close()
    
    # æŒ‰ç±»åˆ«æ‰“å°ç²¾åº¦
    print("\nğŸ“ˆ å„æ•°å­—çš„è¯†åˆ«ç²¾åº¦:")
    for digit in range(10):
        correct = cm[digit, digit]
        total = cm[digit].sum()
        acc = correct / total if total > 0 else 0
        print(f"  æ•°å­—{digit}: {acc*100:.1f}% ({correct}/{total})")


def main():
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    print("åŠ è½½æ¨¡å‹...")
    model = load_model()
    model_with_hooks = NetWithHooks(model).to(DEVICE)
    
    print("åŠ è½½MNISTæµ‹è¯•æ•°æ®...")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    test_dataset = datasets.MNIST(root="./data", train=False, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)
    
    # ==================== åˆ†æ ====================
    
    # 1ï¸âƒ£ å¯è§†åŒ–å·ç§¯æ ¸
    visualize_conv_filters(model)
    
    # 2ï¸âƒ£ é€‰å‡ ä¸ªæ•°å­—ï¼Œçœ‹å®ƒä»¬æ€ä¹ˆè¢«å¤„ç†çš„
    print("\nğŸ¬ é€‰å–ä¸åŒæ•°å­—ï¼Œå¯è§†åŒ–ç‰¹å¾æå–è¿‡ç¨‹...")
    for digit_label in [0, 3, 5, 8]:
        # æ‰¾ä¸€ä¸ªæ ‡ç­¾ä¸ºdigit_labelçš„å›¾åƒ
        for images, labels in test_loader:
            mask = labels == digit_label
            if mask.any():
                test_image = images[mask][0:1].to(DEVICE)
                save_name = f"feature_maps_digit{digit_label}.png"
                visualize_feature_maps(model_with_hooks, test_image, digit_label, save_name)
                break
    
    # 3ï¸âƒ£ æ··æ·†çŸ©é˜µ
    evaluate_and_confusion_matrix(model, test_loader)
    
    print("\n" + "="*50)
    print("âœ… åˆ†æå®Œæˆï¼å·²ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š")
    print("  1. conv_filters.png - Conv1çš„32ä¸ªå·ç§¯æ ¸")
    print("  2. feature_maps_digit*.png - å„æ•°å­—çš„ç‰¹å¾æå–è¿‡ç¨‹")
    print("  3. confusion_matrix.png - æ··æ·†çŸ©é˜µ")
    print("="*50)


if __name__ == "__main__":
    main()
